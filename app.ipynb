{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path):\n",
    "    audio, sample = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "    combined_features = np.hstack([mfccs, chroma, spectral_contrast])\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.99260315e+02  5.30330315e+01 -9.83530140e+00  9.40046406e+00\n",
      " -4.98440742e+00  2.40553474e+00 -1.55293922e+01 -5.46014071e+00\n",
      " -1.43017521e+01 -5.93659353e+00 -3.53338552e+00 -4.39077425e+00\n",
      " -4.36546564e+00 -1.53836858e+00 -8.80753422e+00  1.02889347e+00\n",
      " -9.06821346e+00 -1.52784061e+00 -4.09466505e+00 -3.85637617e+00\n",
      " -6.21353006e+00 -2.29107928e+00 -4.52339602e+00 -4.06523848e+00\n",
      " -3.57221842e+00 -1.47317529e+00 -1.96464956e+00  2.54054379e+00\n",
      "  1.14935911e+00  7.08324015e-01 -1.81262136e+00 -1.92672014e+00\n",
      " -1.13827324e+00  8.19765508e-01  1.83780348e+00  4.72514439e+00\n",
      "  3.00497079e+00  5.00106327e-02 -6.81706488e-01 -1.36187136e+00\n",
      "  4.50462878e-01  5.22485614e-01  5.46331227e-01  4.47947323e-01\n",
      "  5.14102042e-01  5.55319548e-01  5.54396212e-01  5.23587465e-01\n",
      "  4.41024244e-01  4.27330971e-01  5.33335984e-01  4.99350727e-01\n",
      "  2.02411040e+01  1.37914517e+01  1.61740143e+01  1.59664895e+01\n",
      "  1.69325662e+01  1.66128180e+01  3.90445843e+01]\n",
      "                                                 para      label\n",
      "0   [-599.2603149414062, 53.03303146362305, -9.835...      happy\n",
      "1   [-556.0451049804688, 46.025814056396484, -9.27...      happy\n",
      "2   [-575.8170166015625, 50.33829879760742, -9.035...      happy\n",
      "3   [-608.0676879882812, 55.129371643066406, -9.47...      happy\n",
      "4   [-430.5838623046875, 50.10380935668945, -20.36...      panic\n",
      "5   [-406.6454772949219, 46.3847541809082, -21.223...      panic\n",
      "6   [-442.94024658203125, 57.548038482666016, -17....      panic\n",
      "7   [-627.01416015625, 64.70256042480469, -7.57855...  wondering\n",
      "8   [-672.3875732421875, 65.97701263427734, -2.614...  wondering\n",
      "9   [-595.369384765625, 49.243324279785156, -8.462...  wondering\n",
      "10  [-352.3914489746094, 34.60514450073242, -24.71...      angry\n",
      "11  [-372.4840393066406, 28.2077579498291, -24.585...      angry\n",
      "12  [-533.4511108398438, 48.038028717041016, -6.60...      angry\n",
      "13  [-307.7703857421875, 27.7939395904541, -25.707...      angry\n",
      "14  [-405.353515625, 35.1943244934082, -20.9222393...      angry\n",
      "15  [-529.3118286132812, 44.449222564697266, -9.71...      angry\n",
      "16  [-520.3402099609375, 51.73422622680664, -13.90...        sad\n",
      "17  [-629.669677734375, 54.061988830566406, -8.033...        sad\n",
      "18  [-708.2326049804688, 74.10720825195312, -0.502...        sad\n",
      "19  [-608.604248046875, 54.716590881347656, -7.965...        sad\n",
      "20  [-694.5256958007812, 70.3426742553711, -8.5212...        sad\n",
      "21  [-737.16162109375, 74.88166809082031, -0.08566...        sad\n",
      "22  [-700.8250732421875, 71.64476013183594, -4.714...        sad\n",
      "23  [-542.0526123046875, 53.769371032714844, -13.0...        sad\n",
      "24  [-625.6010131835938, 65.5589828491211, 3.51763...       norm\n",
      "25  [-598.2384643554688, 62.16184616088867, -1.875...       norm\n",
      "26  [-573.2510375976562, 48.68437957763672, -4.803...       norm\n",
      "27  [-693.6901245117188, 61.060157775878906, -2.84...       norm\n",
      "28  [-622.2929077148438, 57.918697357177734, -8.62...       norm\n",
      "29  [-695.1851196289062, 58.72072219848633, -4.875...       norm\n",
      "30  [-700.0480346679688, 58.14185333251953, -2.558...       norm\n",
      "31  [-737.82080078125, 63.7191047668457, -6.723161...       norm\n",
      "32  [-714.0130615234375, 62.77835464477539, -2.470...       norm\n",
      "33  [-729.5799560546875, 65.91619110107422, -0.407...       norm\n",
      "34  [-648.197509765625, 66.34977722167969, -7.5913...       norm\n",
      "35  [-701.2548217773438, 72.46028900146484, -2.626...       norm\n",
      "36  [-655.4889526367188, 61.025352478027344, -3.54...       norm\n",
      "37  [-562.0607299804688, 57.9602165222168, -14.572...       norm\n",
      "38  [-633.2892456054688, 65.72415161132812, -8.518...       norm\n",
      "39  [-662.8701171875, 56.39177322387695, -3.822146...       norm\n",
      "40  [-683.2024536132812, 64.19206237792969, -5.312...       norm\n",
      "41  [-605.9327392578125, 58.818199157714844, -9.65...       norm\n",
      "42  [-658.4321899414062, 65.3840560913086, -5.4914...       norm\n",
      "43  [-701.56005859375, 69.03142547607422, -4.60300...       norm\n",
      "44  [-699.91650390625, 69.05924224853516, -2.98459...       norm\n",
      "45  [-548.7622680664062, 46.31926345825195, -9.788...       norm\n",
      "46  [-709.6865234375, 70.09038543701172, -1.068930...       norm\n",
      "47  [-687.2430419921875, 58.96541213989258, -0.275...       norm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = {}\n",
    "paras = []\n",
    "labels = []\n",
    "base_path = \"data/voices\"\n",
    "\n",
    "for label in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, label)\n",
    "    for f in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, f)\n",
    "        try:\n",
    "            features = extract_features(file_path)\n",
    "            paras.append(features)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(paras[0])\n",
    "data.update({'para': paras})\n",
    "data.update({'label': labels})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df.to_csv(\"emotion_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(5), np.int64(1): np.int64(4), np.int64(2): np.int64(17), np.int64(3): np.int64(2), np.int64(4): np.int64(7), np.int64(5): np.int64(3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv(\"emotion_dataset.csv\")\n",
    "\n",
    "df_temp = []\n",
    "for i in df['para']:\n",
    "    frame = [ float(num) for num in (i.strip('[]').split())]\n",
    "    df_temp.append(frame)\n",
    "df['para'] = df_temp\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "x = np.vstack(df['para']) #features\n",
    "y = df['label'].values #labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=1)\n",
    "x_res, y_res = smote.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from knn_emotion_recognition.pkl\n",
      "Accuracy:  30.00%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       0.00      1.00      0.00         0\n",
      "           2       1.00      0.29      0.44         7\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.50      0.55      0.24        10\n",
      "weighted avg       0.90      0.30      0.41        10\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 2 0 1 3]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "file_name = \"knn_emotion_recognition.pkl\"\n",
    "if os.path.isfile(file_name):\n",
    "    knn_model = joblib.load(\"knn_emotion_recognition.pkl\")\n",
    "    print(f\"Model loaded from {file_name}\")\n",
    "else:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2, weights='distance')\n",
    "\n",
    "knn_model.fit(x_res, y_res)\n",
    "\n",
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100: .2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 5],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "best_knn_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_emotion_recognition.pkl']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_knn_model, \"knn_emotion_recognition.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(\"knn_emotion_recognition.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"\"\n",
    "features = extract_features(file_path).reshape(1, -1)\n",
    "\n",
    "predicted_label = loaded_model.predict(features)\n",
    "emotion = label_encoder.inverse_transform(predicted_label)\n",
    "print(f\"Predicted Result: {emotion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
